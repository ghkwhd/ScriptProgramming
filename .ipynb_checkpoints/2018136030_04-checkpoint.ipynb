{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c3e11f",
   "metadata": {},
   "source": [
    "# 2018136030 노화종 Homework#4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e81067",
   "metadata": {},
   "source": [
    "### 1. 다음 문제를 읽고 알맞은 코드를 제시하시오.\n",
    "\n",
    "1) 파일 s.txt 내의 다음 내용과 함께 아래 문제의 코드를 제시하시오.\n",
    " \n",
    ">pig ham  \n",
    "cat dog  \n",
    "ham bird  \n",
    "dog pig  \n",
    "\n",
    "2) 파일 s.txt을 읽어서 각 라인에 있는 첫 번째 단어(문자열) 자체들을 기준으로 라인별 정렬후 파일 s1.txt에 그 결과를 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s1.txt에 있는 파일 내용은 다음과 같다.\n",
    "\n",
    ">cat dog  \n",
    "dog pig  \n",
    "ham bird  \n",
    "pig ham  \n",
    "\n",
    "3) 파일 s.txt을 읽어서 각 라인에 있는 두 번째 단어(문자열) 자체들을 기준으로 라인별 정렬후 파일 s2.txt에 그 결과를 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s2.txt에 있는 파일 내용은 다음과 같다.\n",
    "\n",
    ">ham bird  \n",
    "cat dog  \n",
    "pig ham  \n",
    "dog pig  \n",
    "\n",
    "4) 파일 s.txt을 읽어서 각 라인들에 있는 모든 단어들을 순차적으로 다시 나열하되 각 라인에 세 개의 단어들이 오도록 하여 s3.txt에 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s3.txt에 있는 파일 내용은 다음과 같다.\n",
    "\n",
    ">pig ham cat  \n",
    "dog ham bird  \n",
    "dog pig  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffd2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "str_list = ['pig ham', 'cat dog', 'ham bird', 'dog pig']\n",
    "with open('s.txt', 'w') as f:\n",
    "    for i in str_list:\n",
    "        f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549ef22",
   "metadata": {},
   "source": [
    "* 주어진 단어를 리스트에 저장한다.\n",
    "* 파일을 쓰기모드로 열고 파일이 열린 상태 동안 단어들이 저장된 문자열을 반복하면서 파일에 저장한다.\n",
    "* 리스트가 반복될 때마다 \\n도 같이 저장해서 줄 바꿈이 일어나도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9ccd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "with open('s.txt', 'r') as f1:\n",
    "    list = f1.readlines()\n",
    "list.sort()\n",
    "\n",
    "with open('s1.txt', 'w') as f2:\n",
    "    for i in list:\n",
    "        f2.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b821bff",
   "metadata": {},
   "source": [
    "* 파일을 읽기모드로 열고 readlines()로 파일의 모든 텍스트를 읽어 라인 별로 리스트에 저장한다.\n",
    "* 파일이 닫히면 sort()를 통해 리스트를 정렬한다. 이 때 아무것도 지정되지 않았으므로 가장 첫 번째 단어를 기준으로 정렬된다.\n",
    "* s1.txt파일을 쓰기 모드로 연다. 파일이 없어도 자동으로 생성된다.\n",
    "* 이 역시 1)과 같이 리스트를 반복하며 파일에 저장하는데 이 때 리스트의 각 항목은 개행문자도 포함하고 있기 때문에 개행문자를 붙여주지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4381f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "with open('s.txt', 'r') as f1:\n",
    "    list = f1.readlines()\n",
    "str_list = sorted(list, key = lambda list: list[list.find(' ') + 1])\n",
    "\n",
    "with open('s2.txt', 'w') as f2:\n",
    "    for i in str_list:\n",
    "        f2.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb95c10",
   "metadata": {},
   "source": [
    "* 2)와 같이 저장된 텍스트를 행 별로 리스트에 저장한다.\n",
    "* 리스트를 정렬하는데 sorted를 사용한다.\n",
    "* sorted에서 사용되는 key는 람다함수를 사용했는데 리스트의 항목에서 공백의 인덱스를 찾고 + 1을 해주어 공백 이후 시작되는 문자로 정렬을 하도록 하였다.\n",
    "* 2)와 마찬가지로 리스트를 반복하며 쓰기 모드로 연 파일에 항목을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359863b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "str_list = []\n",
    "new_list = []\n",
    "\n",
    "with open('s.txt', 'r') as f1:\n",
    "    list = f1.readlines()\n",
    "    \n",
    "for i in list:\n",
    "    str_list += i.split()\n",
    "    \n",
    "with open('s3.txt', 'w') as f2:\n",
    "    while True:\n",
    "        if len(str_list) == 0:\n",
    "            break\n",
    "        for i in range(3):\n",
    "            if len(str_list) == 0:\n",
    "                break\n",
    "            f2.write(str_list[0] + ' ')\n",
    "            str_list.remove(str_list[0])\n",
    "        f2.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3fffb",
   "metadata": {},
   "source": [
    "* 텍스트를 읽어 리스트를 만들고 그 리스트를 반복하며 공백으로 나누어주며 새로운 리스트에 저장한다.\n",
    "* s3.txt파일을 쓰기 모드로 열고 반복문을 실행한다.\n",
    "* 반복문이 실행하면서 str_list에 아무 항목이 없으면 반복문을 중단한다.\n",
    "* 만약 항목이 있어 중단되지 않았다면 아래의 for문이 실행되는데 for문은 내부의 코드가 최대 3회 반복된다.\n",
    "* for문 안에서도 역시 str_list가 0인 경우 반복문이 중단되도록 하였는데 세 개씩 단어를 읽다가 항목이 없어지는 경우가 발생하기 때문에 중단시켜주었다.\n",
    "* 만약 중단되지 않았다면 str_list의 첫 번째 인덱스와 공백을 파일에 쓰고 str_list의 첫 번째 인덱스를 삭제한다.\n",
    "* for문이 1회 끝나면 개행문자를 파일에 쓰도록 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0ec30",
   "metadata": {},
   "source": [
    "### 2. 다음과 같은 조건들을 참고하여 회원 가입 및 로그인 프로그램을 작성하시오.\n",
    "1) 프로그램 시작 후 다음과 같은 메시지가 출력되어 1, 2, 3 중 하나의 값을 입력 받도록 한다.\n",
    ">Welcome to Our Service  \n",
    "A. Sign Up  \n",
    "B. Sign In  \n",
    "C. Quit  \n",
    "\n",
    "2) 1을 선택하면 ID, Password, Name, School의 4가지 정보를 입력받아 파일에 저장하는 프로그램을 작성한다.  \n",
    "* 2-1) 입력된 내용은 access.txt 라는 이름의 텍스트 파일 내에 저장된다.\n",
    "* 2-2) access.txt 파일의 각 라인에는 가입된 회원 각각의 정보가 \"[id]: [password], [name], [school]\" 형태로 저장된다.\n",
    "* 2-3) 즉, 가입 회원이 10명이면 access.txt 파일 내에 라인 수도 정확히 10개이다.\n",
    "* 2-4) 암호화 방식은 sha 모듈을 활용한다. sha 모듈 활용 방법은 본 문제의 마지막에 제시된 sha 활용 예를 참고한다.\n",
    "    * 즉, access.txt 파일 내에 password 정보는 암호화 되어 저장되어야 한다.\n",
    "* 2-5) 회원 정보를 입력 받을 때 id를 입력 받은 직후 access.txt를 확인하여 이미 존재하는 id가 입력되었다면 다음 메시지를 출력하고 id 정보를 다시 입력받는다.\n",
    "    * Sorry, the entered ID is already used.\n",
    "* 3) 2를 선택하면 ID, Password의 2가지 정보를 입력받는 프로그램을 작성한다.\n",
    "* 3-1) 입력된 ID 정보가 access.txt에 존재하지 않으면 다음과 같은 메시지를 출력하고 다시 입력받는다.\n",
    "    * Sorry, you are not a registered member.\n",
    "* 3-2) 입력된 ID가 올바르게 존재하지만 Password 정보가 access.txt 파일에 있는 정보와 불일치하면 다음과 같은 메시지를 출력하고 Password를 다시 입력받는다.\n",
    "    * Sorry, the entered password is not correct.\n",
    "    * 이 때에도 사용자가 입력한 Password 정보와 함께 sha 모듈이 활용되어야 한다.\n",
    "* 3-3) 입력된 ID와 Password가 모두 올바르면 다음과 같은 메시지를 출력한다.\n",
    "    * Hello [name]!\n",
    "    * 위 [name]에는 access.txt에 기록되어 있는 name 정보를 출력한다.\n",
    "* 4) 3을 선택하면 프로그램이 끝난다.\n",
    "* [참고] sha 모듈 활용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "pw = \"hello world\"\n",
    "pw_encrypted = hashlib.sha256(pw.encode()).hexdigest()\n",
    "print(pw_encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b399e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Our Service \n",
      "A. Sign Up \n",
      "B. Sign In \n",
      "C. Quit\n",
      "입력 : 3\n",
      "프로그램 종료\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "information = []\n",
    "\n",
    "def check():  #txt 파일에 저장된 정보들을 행 단위로 읽어서 리스트를 만든다.\n",
    "    global information\n",
    "    information = []\n",
    "    with open('access.txt', 'r') as f:\n",
    "            list = f.readlines()\n",
    "    for i in list:\n",
    "        information.append(i.split())\n",
    "\n",
    "choice = int(input('Welcome to Our Service \\nA. Sign Up \\nB. Sign In \\nC. Quit\\n입력 : '))\n",
    "\n",
    "if choice == 1:\n",
    "    signUp = []\n",
    "    \n",
    "    signUp.append(input('ID : '))\n",
    "    while True:\n",
    "        same = 0\n",
    "        check()\n",
    "        for i in range(len(information)):\n",
    "            if signUp[0] == information[i][0]:\n",
    "                same = 1\n",
    "        if same == 0:\n",
    "            break\n",
    "        else:\n",
    "            print('Sorry, the entered ID is already used.')\n",
    "            signUp.remove(signUp[0])\n",
    "            signUp.append(input('ID : '))\n",
    "                    \n",
    "    signUp.append(input('Password : '))\n",
    "    signUp[1] = hashlib.sha256(signUp[1].encode()).hexdigest()\n",
    "    \n",
    "    signUp.append(input('Name : '))\n",
    "    signUp.append(input('School : '))\n",
    "    \n",
    "    with open('access.txt', 'a') as f:\n",
    "        f.write(signUp[0] + ' : ' + signUp[1] + ' , '+ signUp[2] + ' , ' + signUp[3] + '\\n')    \n",
    "    \n",
    "elif choice == 2:\n",
    "    signIn = []\n",
    "    \n",
    "    signIn.append(input('ID : '))\n",
    "    while True:\n",
    "        same = 0\n",
    "        check()\n",
    "        for i in range(len(information)):\n",
    "            if signIn[0] == information[i][0]:\n",
    "                same = 1\n",
    "        if same == 1:\n",
    "            break\n",
    "        else:\n",
    "            print('Sorry, you are not a registered member.')\n",
    "            signIn.remove(signIn[0])\n",
    "            signIn.append(input('ID : '))\n",
    "            \n",
    "    signIn.append(input('Password : '))\n",
    "    signIn[1] = hashlib.sha256(signIn[1].encode()).hexdigest()\n",
    "    while True:\n",
    "        check()\n",
    "        for i in range(len(information)):\n",
    "            if signIn[0] == information[i][0]:\n",
    "                idx = i\n",
    "                break\n",
    "        if information[idx][2] == signIn[1]:\n",
    "            print('Hello ' + information[idx][4] + '!')\n",
    "            break\n",
    "        else:\n",
    "            print('Sorry, the entered password is not correct.')\n",
    "            signIn.remove(signIn[1])\n",
    "            signIn.append(input('Password : '))\n",
    "            signIn[1] = hashlib.sha256(signIn[1].encode()).hexdigest()\n",
    "\n",
    "\n",
    "elif choice == 3:\n",
    "    print('프로그램 종료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da75cf",
   "metadata": {},
   "source": [
    "* 사용자로부터 1,2,3중에 하나를 입력받고 이를 기준으로 조건문이 실행되도록 한다.\n",
    "* check()함수는 txt파일에 저장된 정보들이 저장된 리스트이다. 함수의 시작에서 항상 전역변수로 information리스트를 사용하고 아무것도 없게 초기화를 시킨다. txt파일을 읽기 모드로 읽어 모든 정보를 리스트에 저장하고 이를 공백을 기준으로 나누어 append()를 통해 information리스트에 추가한다.\n",
    "* 사용자가 1을 선택하면 회원가입이 진행되는데 사용자에게 정보들을 입력받기 위해 리스트 하나를 생성한다.\n",
    "* append와 input을 통해 사용자가 입력한 값을 차례대로 리스트에 저장하도록 하였다.\n",
    "* ID를 입력받은 후 ID중복검사를 위한 반복문이 실행되는데 동일 여부를 판단하기 위해 same이라는 변수에 0을 저장한다.\n",
    "* 반복문이 시작되면 check()함수가 호출되고 그 이후 information리스트의 크기만큼 반복하며 리스트의 항목에서 그 항목의 0번째 항목과 입력받은 ID가 같은지를 검사한다.\n",
    "* 만약 같다면 same을 1로 변화시킨다.\n",
    "* 반복문이 끝나고 same이 0이라면 같은 ID가 없기 때문에 반복문을 종료하고 1이라면 입력받은 ID를 지우고 다시 입력받도록 한다.\n",
    "* ID를 입력받은 이후 비밀번호와 이름, 학교를 입력받는데 비밀번호는 hashlib모듈을 추가시켜 이를 통해 암호화시켜 리스트에 저장하도록 하였다.\n",
    "* 모든 정보를 입력받았으면 모든 사용자의 정보가 들어있는 txt파일을 a모드로 열어 입력받은 정보가 저장된 리스트의 항목들을 형식에 맞게 파일에 추가한다.\n",
    "* 로그인이 선택되면 마찬가지로 ID와 pwd를 입력받을 리스트를 선언한다.\n",
    "* 리스트에 ID를 입력받고 사용자가 입력한 ID가 있는지 검사하기 위해 반복문을 실행하고 check()함수를 호출하여 txt파일의 정보들을 information리스트에 저장한다.\n",
    "* information리스트의 크기만큼 반복하며 사용자가 입력받은 ID와 information의 모든 리스트를 돌면서 항목의 0번째 인덱스에 해당하는 항목이 같은지를 검사하고 같다면 same을 1로 변화시키고 같지 않다면 0이 유지되도록 한다.\n",
    "* same이 1이라면 사용자가 입력한 ID가 information에 등록이 되어있기 때문에 반복문을 중단시키고 그렇지 않다면 등록되지 않았다는 메세지를 출력하면서 입력 받은 ID를 삭제하고 다시 ID를 입력받는다.\n",
    "* 비밀번호는 마찬가지로 입력받고 암호화 시킨다.\n",
    "* 비밀번호의 일치여부는 특정 ID에 해당하는 비밀번호와 일치해야한다.\n",
    "* 이 역시 반복문을 통해 확인을 하는데 check()함수 호출 이후, 같은 ID가 있는 인덱스를 반복문을 통해 확인하고 이 인덱스의 2번째 항목 (비밀번호)와 사용자가 입력한 비밀번호를 암호화 시킨 것과 같은지 여부를 검사한다.\n",
    "* 입력한 비밀번호와 저장된 비밀번호가 같다면 사용자가 입력한 이름 (information의 4번째 인덱스)와 함께 Hello [Name]을 출력하고 반복문을 종료한다.\n",
    "* 만약 같지 않다면 비밀번호가 옳지 않다는 메세지와 함게 입력받은 비밀번호를 삭제하고 다시 비밀번호를 입력받은 후 암호화시킨다.\n",
    "* 사용자가 quit항목 (3번)을 선택하면 프로그램을 종료한다는 메세지를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238b746",
   "metadata": {},
   "source": [
    "### 3. range() 함수와 유사한 frange() 함수를 다음 조건을 참고하여 만드시오.\n",
    "\n",
    "1) frange()의 인자 구성은 다음과 같이 range와 동일하지만 각 인수들은 음수를 받지 않는다고 가정한다.\n",
    ">range(stop)  \n",
    "range(start, stop[, step])\n",
    "\n",
    "* 2) frange() 함수의 인자에 대한 기본 시작(start) 값은 0.0이고, 기본 단계(step) 값은 0.1이다.  \n",
    "* 3) frange 사용 예\n",
    "    * 3-1) frange(0.5)\n",
    "        * [0.0, 0.1, 0.2, 0.3, 0.4]  \n",
    "    * 3-2) frange(1.0, 2.0)\n",
    "        * [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]  \n",
    "    * 3-3) frange(2.2, 4.0, 0.5)\n",
    "        * [2.2, 2.7, 3.2, 3.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075bbf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, 0.2, 0.3, 0.4]\n",
      "[1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]\n",
      "[2.2, 2.7, 3.2, 3.7]\n"
     ]
    }
   ],
   "source": [
    "def frange(start, stop = -1, step = 0.1):\n",
    "    num_list = []\n",
    "    if stop == -1:\n",
    "        stop = start\n",
    "        start = 0.0\n",
    "        \n",
    "    while True:\n",
    "            if start >= stop:\n",
    "                break\n",
    "            num_list.append(start)\n",
    "            start += step\n",
    "            start = round(start, 1)\n",
    "        \n",
    "    return num_list\n",
    "\n",
    "print(frange(0.5))\n",
    "print(frange(1.0, 2.0))\n",
    "print(frange(2.2, 4.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22918995",
   "metadata": {},
   "source": [
    "* 키워드 인수를 통해 stop, step에 각 값을 지정해준다. 이 때, 한 개가 들어온 것을 알기 위해 stop에는 절대 나오지 않는 음수를 지정한다.\n",
    "* 만약 stop이 1이라면 한 개의 인수만 들어온 것이기 때문에 start를 0.0으로, 들어온 값을 stop으로 바꾸어준다.\n",
    "* 반복문에서는 start가 stop 보다 커지면 중단하고 그렇지 않은 경우 아래의 코드가 실행되기 때문에 아래에 리스트에 숫자들을 추가하고 start와 step을 더해주어 서서히 값이 step만큼 커지도록 하였으며 마지막에는 리스트를 반환하였다.   \n",
    " \n",
    " \n",
    "* 그냥 실행을 했을 때, 0.3000000000002처럼 뜨는 경우도 있어서 round를 통해 start를 소수점 한 자리 수까지만 저장하도록 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c710c0",
   "metadata": {},
   "source": [
    "### 4. 가변인수를 받는 함수 sum()을 다음과 같은 조건을 참고하여 구현하시오\n",
    "\n",
    "* sum() 사용 예\n",
    "\n",
    ">sum()  \n",
    ">0  \n",
    ">  \n",
    ">sum(1, 2)   \n",
    ">3  \n",
    ">\n",
    ">sum(1, 2, 3, 4, 5)  \n",
    ">15  \n",
    ">\n",
    ">sum(1, 5, 7, 2, -10)  \n",
    ">5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2a3217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum(*args):\n",
    "    result = 0\n",
    "    for i in args:\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "\n",
    "sum(1, 5, 7, 2, -10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7bdd90",
   "metadata": {},
   "source": [
    "* 함수의 인수 부분에 가변인수를 선언하여 반복문이 가변인수를 반복하며 result라는 변수 안에 값을 계속해서 더해주는 방식으로 진행하였으며 모든 인수에 대한 반복이 끝나면 값을 저장한 result를 반환해주었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2acc328",
   "metadata": {},
   "source": [
    "### 5. 여러 단어로 이루어진 문자열을 입력받아 각 단어의 첫글자로 이루어진 단어를 대문자로 출력하는 myinitial() 함수를 다음 조건을 참고하여 작성하시오.\n",
    "\n",
    "* 1) 다음에 제시되는 함수들을 모두 이용해야 한다.\n",
    "\n",
    "    * split\n",
    "    * map\n",
    "    * join   \n",
    "     \n",
    "     \n",
    "* 2) myinitial() 함수 사용 예\n",
    "    * myinitial(\"as soon as possible\")\n",
    "        * ASAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7698b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열 입력 : as soon as possible\n",
      "ASAP\n"
     ]
    }
   ],
   "source": [
    "def  myinitial(str):\n",
    "    str_list = str.split()\n",
    "    initial_list = list(map(lambda x : x[0], str_list))\n",
    "    for i in range(len(initial_list)):\n",
    "        initial_list[i] = initial_list[i].upper()\n",
    "    initial = ''.join(initial_list)\n",
    "    print(initial)\n",
    "    \n",
    "str = input(\"문자열 입력 : \")\n",
    "myinitial(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135aa0d1",
   "metadata": {},
   "source": [
    "* 입력받은 문자열을 myinitial()에 전달한다.\n",
    "* 전달받은 문자열을 split()를 통해 공백을 기준으로 나누어 리스트에 저장한다.\n",
    "* 저장된 리스트를 map과 람다함수를 통해 첫 글자만을 가진 리스트를 만든다.\n",
    "* 첫 글자만 가진 리스트 크기만큼 반복하며 대문자로 변환한다.\n",
    "* 대문자로 변환된 리스트를 join을 통해 문자열로 변환하고 이를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c359bd",
   "metadata": {},
   "source": [
    "### 6. 음이 아닌 정수 n를 입력받으면 n! (factorial)을 계산하는 myfact() 함수를 재귀적 함수로 구현하시오.\n",
    "* [옵션] 참을 수 있는 정도 만큼의 수행시간을 직접 기다려보면서 n을 늘려보도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f8c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281710411438055027694947944226061159480056634330574206405101912752560026159795933451040286452340924018275123200000000000000000000\n"
     ]
    }
   ],
   "source": [
    "def myfact(num) :\n",
    "    if type(num) != int:\n",
    "        return \"정수 값을 입력해야합니다,\"\n",
    "    else:\n",
    "        if num < 0:\n",
    "            return \"음이 아닌 정수를 입력해야합니다.\"\n",
    "        \n",
    "        elif num == 0 or num == 1 : \n",
    "            return 1     \n",
    "        \n",
    "        else : \n",
    "            return num * myfact(num - 1)\n",
    "    \n",
    "print(myfact(85))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43511f73",
   "metadata": {},
   "source": [
    "* 전달 받은 숫자가 정수인지 type()을 통해 검사한 후 정수가 아니라면 정수 값을 입력해야한다는 문자열을 반환\n",
    "* 정수일 때, 만약 숫자가 음수라면 음이 아닌 정수를 입력해야한다는 문자열을 반환\n",
    "* 숫자가 0이거나 1이면 1을 반환하고 그보다 크다면 n-1한 값으로 다시 함수를 호출한다.  \n",
    "\n",
    "\n",
    "* 2959부터 RecursionError: maximum recursion depth exceeded while calling a Python object가 뜨는 것을 확인하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c1e96",
   "metadata": {},
   "source": [
    "### 7. (서술형) import string 과 from string import * 의 차이점을 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c5c56",
   "metadata": {},
   "source": [
    "* import string는 모듈이름을 그대로 이름 공간에 등록하는 것이므로 string모듈의 함수를 사용할 때, string.XX로 사용해야한다. \n",
    "* 반면 from string import * 를 사용하면 모듈의 이름공간에 존재하는 객체를 그대로 이름공간에 등록하기 때문에 함수 이름만으로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d650c22",
   "metadata": {},
   "source": [
    "### [Incremental Project 문제]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34d56c",
   "metadata": {},
   "source": [
    "**이전 Assignment 3의 마지막 문제는 웹 URL로 지정된 웹페이지를 문자열로 가져와 모든 HTML 태그 및 CSS와 Javascript를 제외한 순수 텍스트를 얻어내고 그 안에 존재하는 단어를 추출하여 각 단어들에 대해 출현빈도를 사전형태({'world': 2, 'hello': 1, 'python': 1})로 저장하여 출력하는 것이었다. 이번에는 Assignment 3를 확장하여 다음과 같은 조건을 만족하도록 구현하시오.**\n",
    "* 1) 다음 사이트에서 제시되는 불용어 (Stop words)를 참고하여 이전 숙제에서 구성했던 단어 사전에서 불용어들을 모두 제거하는 코드를 추가하시오.\n",
    "    * 영어 불용어: http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "    * 한글 불용어: https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt\n",
    "* 2) 각 URL로 지정된 웹페이지의 HTML 소스를 파일로 저장하시오.\n",
    "    * URL이 http://URL 이라면 파일명은 URL.html 이다.\n",
    "        * 예: URL이 http://www.cnn.com 이라면 파일명은 www.cnn.com.html 이다.\n",
    "* 3) 단어의 출현빈도가 담긴 사전 객체를 위 HTML 소스 파일과 동일한 폴더에 파일로 저장하시오.\n",
    "    * 파일입출력 (E-learning 13주차) 마지막에 학습한 pickle 모듈을 활용하시오.\n",
    "    * URL이 http://URL 이라면 사전 객체를 담고 있는 파일명은 URL.words_frequency.pickle 이다.\n",
    "        * 예: URL이 http://www.cnn.com 이라면 파일명은 www.cnn.com.words_frequency.pickle 이다.\n",
    "* 4) 최소 5개 이상의 웹 사이트 각각에 대한 HTML 소스 파일과 단어 출현빈도 파일을 저장하시오.\n",
    "    * 즉, 5개의 웹 사이트에 대해 총 10개의 파일을 동일한 폴더에 생성하시오.\n",
    "    * [주의] 가능하면 웹사이트에 단어들이 많고 다루는 주제가 서로 다른 웹 사이트들로 선정하는 것 추천\n",
    "* 5) 위 문제에서 저장한 모든 pickle 파일들을 객체로 다시 로드하여 본인이 저장하여 분석한 사이트들 각각에 대해서 가장 많이 출현한 단어 3개씩를 뽑아 제시하시오.\n",
    "    * 반드시 pickle 모듈로 저장한 5개 이상의 pickle 파일들을 다시 5개 이상의 사전 객체로 로드 하는 코드가 추가되어야 함\n",
    "* 6) 간단한 검색엔진 코딩 (Like Google!!!)\n",
    "    * 사용자에게 임의의 검색어 (하나 또는 여러 단어로 구성) 를 입력받으시오.\n",
    "        * 예:\n",
    "            * 대한민국\n",
    "            * 컴퓨터 공학\n",
    "            * 맛있는 음식\n",
    "            * 파이썬\n",
    "            * 한기대 장점\n",
    "    * 입력받은 검색어들에 대해서도 1)에서 제시하는 방법처럼 불용어 처리를 하여 정리\n",
    "    * 입력 받은 검색어와 유사도(Similarity)가 높은 웹 사이트 기준으로 위 4)에서 미리 지정해 놓은 5개 이상의 웹 사이트 URL들을 일렬로 나열하여 출력하시오.\n",
    "        * 검색어와 웹 사이트 간의 유사도는 본인이 스스로 정하시오.\n",
    "        * 유사도를 정하는 최소한의 기준은 단어 출현 빈도를 기반으로 해야 하며, 이외의 본인이 생각하는 방안이 있으면 함께 사용해도 됨.\n",
    "        * 유사도가 높은 웹 사이트가 상위에 출력되어야 함 (즉, 유사도 기준 내림 차순)\n",
    "        * 유사도가 동일한 웹 사이트들에 대해서는 임의 배치함.\n",
    "* 7) [주의] 필수사항\n",
    "    * 위에서 만든 검색엔진 코딩은 매우 간단한 것이라 부족한 점이 많이 존재한다.\n",
    "    * 본인이 생각하기에 상업적인 완성도 높은 검색 로봇/엔진이 되려면 어떤 기능들이 추가적으로 구현되어야 할지 최소 1가지 이상 제시하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96828aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.weather.go.kr에서 찾은 글자 수 >> 711 , 빈도 수가 높은 단어 3개 >> (있습니다 :  21번), (또는 :  12번), (날씨누리 :  11번), \n",
      "www.daum.net에서 찾은 글자 수 >> 529 , 빈도 수가 높은 단어 3개 >> (날씨 :  21번), (맑음 :  19번), (영상 :  19번), \n",
      "www.koreatech.ac.kr에서 찾은 글자 수 >> 525 , 빈도 수가 높은 단어 3개 >> (한국기술교육대학교 :  14번), (대학 :  10번), (KOREATECH :  9번), \n",
      "www.bok.or.kr에서 찾은 글자 수 >> 754 , 빈도 수가 높은 단어 3개 >> (한국은행 :  41번), (2021년 :  34번), (안내 :  22번), \n",
      "www.naver.com에서 찾은 글자 수 >> 2954 , 빈도 수가 높은 단어 3개 >> (책방 :  61번), (구독 :  26번), (해지 :  24번), \n",
      "www.nytimes.com에서 찾은 글자 수 >> 889 , 빈도 수가 높은 단어 3개 >> (Times :  34번), (York :  32번), (Queue :  9번), \n",
      "www.koroad.or.kr에서 찾은 글자 수 >> 792 , 빈도 수가 높은 단어 3개 >> (도로교통공단 :  13번), (일자리 :  10번), (영문 :  10번), \n",
      "검색할 문자열 입력 : 금리\n",
      "유사도에 따른 url 출력\n",
      "http://www.bok.or.kr , 유사도 :  0.010610079575596816\n",
      "https://www.daum.net , 유사도 :  0.000945179584120983\n",
      "https://www.weather.go.kr , 유사도 :  0.0\n",
      "https://www.koreatech.ac.kr , 유사도 :  0.0\n",
      "https://www.naver.com , 유사도 :  0.0\n",
      "http://www.nytimes.com , 유사도 :  0.0\n",
      "https://www.koroad.or.kr , 유사도 :  0.0\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "# 전달받은 문자열 사이의 구간 삭제\n",
    "def delete(string, first, second):\n",
    "    while (True):\n",
    "        start = string.find(first)  # first에 들어온 단어의 위치 확인\n",
    "        end = string.find(second)  # end로 들어온 단어의 위치 확인\n",
    "        if start != -1 and end != -1:\n",
    "            string = string[:start] + string[end + len(second):]  # end는 시작되는 위치가 나오기 때문에 end는 글자수 만큼 더해준다\n",
    "        elif start == -1 and end == -1:\n",
    "            break\n",
    "    return string\n",
    "\n",
    "\n",
    "def find_word(str):\n",
    "    list = []  # 태그를 제거한 리스트\n",
    "    word = []  # 공백을 기준으로 나눈 리스트\n",
    "    result = []  # 특수문자, 숫자, 기타 문법을 제거한 최종 리스트\n",
    "    dic = {}\n",
    "    temp = []  # 단어 저장을 위한 임시 리스트\n",
    "\n",
    "    # 태그 사이에 문법이 들어가는 경우의 삭제\n",
    "    # 간혹 대문자로 쓰인 페이지가 있어서 대문자로 이루어진 태그도 구간 삭제\n",
    "    str = delete(str, '<style', '</style>')  # <style ~ </style> 구간 삭제\n",
    "    str = delete(str, '<STYLE', '</STYLE>')  # <STYLE ~ </STYLE> 구간 삭제\n",
    "    str = delete(str, '<script', '</script>')  # <script ~ </script> 구간 삭제\n",
    "    str = delete(str, '<SCRIPT', '</SCRIPT>')  # <SCRIPT ~ </SCRIPT> 구간 삭제\n",
    "    str = delete(str, '<!--', '-->')  # 주석처리 구간 삭제\n",
    "\n",
    "    # HTML 태그 제거\n",
    "    while (True):\n",
    "        start = str.find('<')  # <가 있는 위치 확인\n",
    "        end = str.find('>')  # >가 있는 위치 확인\n",
    "        if start == -1 and end == -1:  # 만약 < 와 > 가 없다면\n",
    "            break  # 모든 문자열을 확인한 것이니 반복문 중단\n",
    "        # <> 내부에 <>가 있는지 확인\n",
    "        inner = str[start + 1: end + 1]  # <>사이를 자른 문자열 생성\n",
    "        in_start = inner.find('<')  # <가 있는 위치 확인\n",
    "        if in_start != -1:  # <> 사이에 <가 있다면 < <> > 형태이므로\n",
    "            str = str[:in_start] + str[end + 1:]  # 내부의 <> 삭제\n",
    "            continue\n",
    "        list.append(str[:start])  # 반복문이 중단되지 않았다면 처음부터 start 전까지의 문자열을 list에 저장\n",
    "        str = str[end + 1:]  # > 이후의 문자열만 남긴다\n",
    "\n",
    "    # &gt, &lt 등 삭제\n",
    "    i = 0\n",
    "    while (True):\n",
    "        start = list[i].find('&')  # 시작이 &\n",
    "        end = list[i].find(';')  # 끝이 ;\n",
    "        if start != -1 and end != -1:  # 둘 다 발견되었을 경우\n",
    "            if start < end:  # &가 앞에서, ;가 뒤에서 발견된 경우\n",
    "                list[i] = list[i][:start] + list[i][end + 1:]  # &와 ; 사이의 구간을 삭제\n",
    "            else:  # ; 하나만 쓰여서 &가 뒤에서 발견되는 경우 (나중에 특수문자에서 제거된다)\n",
    "                i += 1  # 다음 항목으로 넘어간다\n",
    "        else:  # 발견되지 않았을 경우\n",
    "            i += 1  # 다음 단어 확인\n",
    "\n",
    "        if i == len(list):  # 마지막 단어까지 확인하면 중단\n",
    "            break\n",
    "\n",
    "    # 공백을 통해 임시로 단어 나누기\n",
    "    for i in range(len(list)):\n",
    "        temp = list[i].split()  # 리스트의 항목을 반복시켜 공백으로 나누고 임시 리스트에 저장\n",
    "        for j in range(len(temp)):  # 임시 리스트의 항목 수 만큼 반복\n",
    "            word.append(temp[j])  # 임시 리스트의 내용들을 word 리스트에 저장\n",
    "\n",
    "    # string.punctuation을 이용하여 구두문자 제거\n",
    "    for i in word:\n",
    "        i = i.replace(string.punctuation, ' ')\n",
    "\n",
    "    # string.punctuation으로 제거되지 않은 특수문자 제거\n",
    "    for i in range(len(word)):\n",
    "        k = 0\n",
    "        while (True):\n",
    "            if not word[i][k].isalnum():  # 문자(영어, 한글)나 숫자로만 이루어진 경우가 아닐 때\n",
    "                if word[i][k] != '' and word[i][k] != ' ':  # 아무것도 없는 항목이거나 공백만 들어있는 것이 아닐 때\n",
    "                    word[i] = word[i].replace(word[i][k], ' ')  # 해당 위치를 공백으로 변경\n",
    "                else:  # 아무것도 들어있지 않거나 공백이라면\n",
    "                    k += 1  # 단어의 다음 위치 확인\n",
    "            else:  # 문자와 숫자로만 이루어진 경우\n",
    "                k += 1  # 문자의 다음 위치 확인\n",
    "\n",
    "            if k == len(word[i]):  # 문자열의 마지막 부분까지 확인했다면\n",
    "                break  # 반복 중단\n",
    "\n",
    "    # 구두문자 제거 이후 공백 항목 제거\n",
    "    for i in range(len(word)):\n",
    "        temp = word[i].split()  # word 항목을 반복시켜 공백으로 나누고 임시 리스트에 저장\n",
    "        for j in range(len(temp)):  # 임시 리스트의 항목 수 만큼 반복\n",
    "            result.append(temp[j])  # 임시 리스트의 내용들을 result 리스트에 저장\n",
    "\n",
    "    # 숫자만으로 이루어진 항목 제거\n",
    "    i = 0\n",
    "    while (True):\n",
    "        if result[i].isdigit():  # 항목이 숫자로만 구성되어 있다면 True를 반환해서 조건문 실행\n",
    "            result.remove(result[i])  # 숫자만으로 구성된 항목은 삭제\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        if i == len(result):\n",
    "            break\n",
    "\n",
    "    # 각 단어의 출현 빈도를 사전형태로 저장\n",
    "    for i in result:\n",
    "        dic[i] = dic.get(i, 0) + 1\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "def makeStopWord():\n",
    "    stop_word = []\n",
    "    # 한글 불용어 리스트에 저장\n",
    "    req = requests.get('https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt')\n",
    "    source = req.text\n",
    "    stop_word = list(source)  # 한글 불용어를 리스트에 저장\n",
    "\n",
    "    with open('stop_words_english.txt', 'r', encoding='UTF-8') as file:\n",
    "        file_list = file.readlines()  # txt 파일로 저장된 영어 불용어들을 읽어 리스트에 저장\n",
    "\n",
    "    for i in range(len(file_list)):  # 파일을 읽고 저장한 리스트에서 개행문자 제거\n",
    "        file_list[i] = file_list[i].rstrip('\\n')\n",
    "\n",
    "    stop_word += file_list  # 한글과 영문이 합쳐진 불용어\n",
    "\n",
    "    return stop_word\n",
    "\n",
    "\n",
    "def deleteStopWord(dic, stop_word):  # 불용어 삭제 함수\n",
    "    for i in stop_word:  # 불용어들을 반복하면서\n",
    "        if i in dic:\n",
    "            del dic[i]\n",
    "\n",
    "    # 영어 불용어를 대, 소문자에 관계없이 제거하기 위해 선언\n",
    "    engKeys = []\n",
    "    for k in dic.keys():\n",
    "        str_key = str(k)\n",
    "        if str_key.encode().isalpha():\n",
    "            engKeys.append((k,str_key.lower()))\n",
    "\n",
    "    for i in stop_word:\n",
    "        for j in engKeys:\n",
    "            if i == j[1]:\n",
    "                del dic[j[0]]\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "def makeHTML(url, url_name):  # html소스를 파일에 저장\n",
    "    req = requests.get(url)\n",
    "    html_source = req.text\n",
    "\n",
    "    with open(url_name + '.html', 'w', encoding='UTF-8') as file:\n",
    "        file.write(html_source)\n",
    "\n",
    "    # html 소스를 리턴 ( 사전 형태의 단어 출현빈도를 만들기 위해 )\n",
    "    return html_source\n",
    "\n",
    "\n",
    "def make_frequencyFile(url_name, dic):\n",
    "    with open(url_name + '.words_frequency.pickle', 'wb') as file:\n",
    "        pickle.dump(dic, file)\n",
    "\n",
    "\n",
    "def load_pickle(url_name):\n",
    "    with open(url_name + '.words_frequency.pickle', 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                load = pickle.load(file)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    sorted_list = sorted(load.items(), key= lambda x : x[1], reverse = True)    # 사전의 값으로 내림차순 형태로 정렬\n",
    "\n",
    "    print(url_name + '에서 찾은 글자 수 >>', len(load), ', 빈도 수가 높은 단어 3개 >> ', end='')\n",
    "    for i in range(3):\n",
    "        print('(' + sorted_list[i][0] + ' : ', str(sorted_list[i][1]) + '번)', end=', ')\n",
    "    print()\n",
    "\n",
    "\n",
    "def similarity(searchWord, dic, num):\n",
    "    # 단어 수에 의한 빈도 수\n",
    "    similar = 0.0\n",
    "    if len(searchWord) == 0:\n",
    "        return similar\n",
    "    else:\n",
    "        for i in searchWord:    # 단어 일치 여부를 기준으로 한 유사도 판단\n",
    "            if i in dic:\n",
    "                value = dic[i]\n",
    "                similar += value / num # num : 단어들의 빈도 수의 합\n",
    "\n",
    "        similar = similar / len(searchWord)\n",
    "\n",
    "        for i in searchWord:\n",
    "            for j in dic.keys():\n",
    "                str_keys = str(j)\n",
    "                if i in str_keys: # 단어 포함 여부를 판단으로 한 유사도 판단\n",
    "                    value = dic[j]\n",
    "                    similar += (value / num) * 0.5 # 포함 여부는 검색의 정확성이 일치여부보다 낮기 때문에 0.5를 곱해준다\n",
    "\n",
    "        similar = similar / len(searchWord)\n",
    "\n",
    "        return similar\n",
    "\n",
    "\n",
    "def search(url, stop_word, dic, sumWords):\n",
    "    similarityDict = {}\n",
    "    find = input('검색할 문자열 입력 : ')\n",
    "    find = find.split() # 검색 문자열 공백을 기준으로 나누기\n",
    "\n",
    "    for i in stop_word:\n",
    "        if i in find:   # 입력한 검색어에 대한 불용어처리\n",
    "            find.remove(i)\n",
    "\n",
    "    for i in range(len(url)):\n",
    "        similar = similarity(find, dic[i], sumWords[i])  # 유사도 판단\n",
    "        similarityDict[url[i]] = similar   # 사전에 추가\n",
    "\n",
    "    sorted_list = sorted(similarityDict.items(), key=lambda x: x[1], reverse=True)  # 사전을 값의 내림차순 형태로 정렬\n",
    "\n",
    "    return sorted_list\n",
    "\n",
    "def lenDict(dic):\n",
    "    sum = 0\n",
    "    for i in dic.values():\n",
    "        sum += 1\n",
    "    return sum\n",
    "\n",
    "\n",
    "urlList = ['https://www.weather.go.kr', 'https://www.daum.net', 'https://www.koreatech.ac.kr', 'http://www.bok.or.kr',\n",
    "           'https://www.naver.com', 'http://www.nytimes.com', 'https://www.koroad.or.kr']\n",
    "\n",
    "dicList = []    # 단어들의 빈도가 저장된 사전 객체를 저장하는 리스트\n",
    "sum = []    # 단어들의 수를 저장하는 리스트\n",
    "\n",
    "stop_word_list = makeStopWord()  # 불용어 리스트 생성\n",
    "\n",
    "for i in urlList:\n",
    "    name = i.replace('http://', '')  # http:// 제거\n",
    "    name = name.replace('https://', '')  # https:// 제거\n",
    "\n",
    "    source = makeHTML(i, name)  # html 파일 생성\n",
    "\n",
    "    words = find_word(source)  # 단어를 사전 형태로 생성\n",
    "\n",
    "    words = deleteStopWord(words, stop_word_list)  # 생성된 사전에서 불용어 제거\n",
    "\n",
    "    dicList.append(words)   # 사전 객체를 리스트에 추가\n",
    "\n",
    "    make_frequencyFile(name, words)  # 사전 형태의 객체를 파일에 저장\n",
    "\n",
    "    load_pickle(name) # 가장 빈도 수가 많은 단어 세 개를 출력\n",
    "\n",
    "    sum.append(lenDict(words))  # 사전 객체에 있는 모든 빈도 수들의 합\n",
    "\n",
    "# 입력받은 검색어에 대해 url과 유사도를 정렬된 형태로 반환된 리스트를 저장\n",
    "sortedList = search(urlList, stop_word_list, dicList, sum)\n",
    "\n",
    "print('유사도에 따른 url 출력')\n",
    "for i in sortedList:\n",
    "    print(i[0], ', 유사도 : ', i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02125e",
   "metadata": {},
   "source": [
    "7)\n",
    "* 완성도 높은 검색 로봇/엔진이 되려면 사용자가 입력한 단어에 대해 페이지를 찾으면 그 페이지의 단어들을 유사한 단어들로 지정하고 후에 같은 단어를 검색했을 때, 혹은 유사한 단어들을 검색했을 때, 이전 검색어 혹은 유사어들도 고려하여 유사도를 계산한다면 조금 더 좋을 것 같다.\n",
    "* 검색을 했을 때 보여지는 페이지 역시, 사용자가 자주 방문한 웹의 검색 결과를 가장 위 쪽에 배치하는 것도 나쁜 방식은 아니라고 생각한다.\n",
    "* 검색의 키워드를 판단할 수 있으면 좋을 것 같다. 키워드의 판단은 예를 들어, 한기대 장점을 검색했을 때, 한기대를 검색했을 때 장점이라는 단어가 많이 나오는지, 장점을 검색했을 때 한기대가 많이 나오는지를 비교하여 키워드를 판단하는 방법도 있을 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1b4c4",
   "metadata": {},
   "source": [
    "* 한글, 영문 모든 불용어를 저장하는 리스트를 선언하기 위해 makeStopWord()함수를 호출하여 반환되는 값을 stop_word_list라는 리스트에 저장하였다.\n",
    "* makeStopWord()는 한글 불용어가 있는 url의 소스를 가져와서 리스트에 저장하면 소스가 불용어들로 이루어져있기 때문에 리스트의 항목으로 하나씩 저장된다.\n",
    "* 영문 불용어를 제거하기 위해 미리 불용어가 저장된 txt파일을 다운받았고, 이 파일을 읽기모드로 열어 readlines()를 통해 모든 불용어들을 리스트에 저장시키고 이 리스트를 반복하며 rstrip()을 통해 개행문자 '\\n'을 제거하도록 하였다. 그 후 한글 불용어 리스트와 영문불용어 리스트를 합하여 전체 불용어 리스트를 만들었다.\n",
    "* 7개의 URL에 대해 파일 이름으로 설정할 수 있도록 https://, http://를 제거하였고 html파일 생성, 단어들을 사전 객체로 생성, 생성된 사전에서 불용어 제거, 사전 객체를 파일에 저장, 가장 빈도 수가 많은 세 개의 단어 출력을 반복문 내에서 진행하였고, 또한 검색엔진에서 사용하기 위해 따로 리스트를 선언하여 반복문을 통해 생성되는 사전 객체와 사전 객체의 모든 값의 합을 서로 다른 리스트에 저장하였다.\n",
    "* 그리고 html파일을 생성하는데 makeHTML의 인수로 url과 url의 이름을 가져와서 url이 소스를 가져와 파일을 쓰기 모드로 열고 write()를 이용해 파일에 쓴다. 그리고 이 소스를 이용해 단어 빈도 수를 구하기 위해 소스를 리턴해준다.\n",
    "* 이 리턴된 소스를 source로 저장하여 find_word()에 전달하여 단어 빈도 수를 가지고 있는 사전 객체를 생성하도록 한다.\n",
    "* 이 생성된 사전 객체를 불용어를 제거하기 위해 deleteStopWord()에 저장한다.\n",
    "* deleteStopWord()는 사전 객체와 불용어 리스트를 받아와 불용어 리스트를 반복하며 불용어가 사전 객체에 있다면 그 키와 값을 삭제하도록 진행하였다.\n",
    "* 그리고 영어 단어가 적힌 경우, 대,소문자를 구분하지 못하기 때문에 사전의 키 값들을 반복하며 키 값을 문자열로 변환한 str_key를 선언하고 알파벳인지 확인한다. isalpha()의 경우, 한글이여도 True가 출력되기 때문에 영문인지 확인을 위해 encode().isalpha()를 사용하였으며 이것이 True일 때, engKeys에 원래의 키 값과 함께 키 값을 소문자로 변환한 키 값을 튜플형태로 리스트에 추가한다.\n",
    "* 이제 불용어를 반복하면서 내부에서 engKeys()를 반복하고 i(불용어)와 j[1] (소문자로 변환된 키 값)이 같다면 사전 객체에서 삭제하도록 하였다.\n",
    "* 그렇게 완성된 words라는 사전 객체를 dicList에 추가하는데 반복문이 끝나면 dicList는 각 항목이 사전 객체를 가지고 있게 된다.\n",
    "* 사전 객체를 파일에 저장하기 위해 make_frequency()를 호출하는데 파일 이름과 사전 객체를 인수로 전달한다.\n",
    "* make_frequencyFile()은 wb형태로 파일을 열고 pickle모듈의 dump()를 이용하여 파일에 객체를 저장시킨다.\n",
    "* 사전 객체를 불러와 가장 빈도 수가 많은 세 개의 단어를 출력하기 위해 name을 인자로 보내 load_pickle()를 호출한다.\n",
    "* 전달받은 이름을 통해 파일을 rb로 열고 무한 반복을 실행한다. 이 때 load()를 이용하여 객체를 가져오는데 파일에 객체가 얼마나 가지고 있는지 알 수 없고, 더 이상 객체를 가져올 수 없을 때, EOFError이 발생하기 때문에 except를 통해 저 에러가 발생하면 반복문이 중단되도록 한다.\n",
    "* load객체에 load 시켰기 때문에 load는 사전 객체이다. 이를 sorted()를 통해 정렬하는데 key 값은 lambda함수로 정의하는데 빈도 수를 키 값으로 가지게 하고 reverse를 True로 설정하여 빈도 수의 내림차순으로 정렬되게 하였고, 3번의 반복문을 통해 가장 많이 출현된 단어 세 개를 출력하도록 하였다.\n",
    "* 사전 객체가 가지고 있는 모든 값들의 합 즉, 모든 단어가 출현된 횟수를 저장하기 위해 sum이라는 리스트에 lenDIct()의 결과값을 추가한다. lenDict는 사전 객체를 인자로 받아 값들을 반복하며 모두 더해주고 더한 값을 반환하는 함수이다.\n",
    "* 모든 url에 대한 지금까지의 과정이 끝나면 사용자에게 검색을 입력받아 유사도를 계산하기 위해 search()함수를 호출한다. 이 함수는 url들이 저장된 리스트, 불용어 리스트, 사전 객체들이 저장된 리스트, 각 url에서 추출한 단어 수들의 합이 저장된 리스트를 인수로 갖는다.\n",
    "* search()함수에서 url을 키 값으로 가지고, 유사도를 값으로 가지는 similarDict 사전 객체를 선언한다. \n",
    "* find객체에 사용자로부터 검색어를 입력받고, 이를 split()을 통해 공백을 기준으로 나누어 리스트로 만든다. 그리고 불용어 리스트를 반복하며 불용어가 이 find에 존재하면 삭제하는 방식으로 검색어에 대한 불용어 제거를 진행한다.\n",
    "* 불용어를 제거하고 url의 길이만큼 반복하면서 유사도를 계산하는 similartity()를 호출하고 반환된 유사도를 값으로 가지고, url을 키로 가지도록 사전 객체에 추가한다.\n",
    "* similarity()는 검색어와 단어 수에 대한 사전 객체를 가진 리스트의 i번째 항목, 단어 출현 횟수가 저장된 리스트의 i번째 항목을 인수로 갖는다.\n",
    "* 이 함수에서 similar를 0.0으로 초기화 시키는데 이는 유사도를 나타낸다. 이 때 전달받은 검색어의 길이가 0이라면 바로 similar를 반환하도록 한다. 이 경우는 검색어가 불용어로만 이루어져 있어 검색어가 사라진 경우이다. 그것이 아니라면 유사도를 판단한다.\n",
    "* 유사도를 판단하기 위해 두 가지 방식을 사용했는데 첫 번째는 사전의 키 값과 단어가 일치하는지를 판단하는 것이고, 두 번째 방식은 검색어가 사전 객체의 키 값을 이루는 문자열에 포함이 되는지를 판단하는 방법을 사용하였다.\n",
    "* 단어가 일치하는지 확인하기 위해 검색어 리스트를 반복하면서 i(검색어)가 사전 객체에 포함되어 있다면 해당 키에 대한 값을 value에 저장하고 similar에 value/전체 단어 수의 합을 더해준다. 그리고 반복문이 끝나면 similar를 검색어 리스트의 크기만큼 나누어 similar의 값을 다시 정해준다.\n",
    "* 단어 포함여부 판단을 위해 이중 반복문을 사용하는데 외부는 불용어를 반복하고 내부는 사전의 키를 반복한다. 사전의 키가 반복되는 j를 문자열화 시켜 str_keys에 저장하고 검색어 i가 str_keys에 포함된다면 키에 대한 값을 value에 저장하고 이를 전체 단어의 수로 나눈 후 0.5를 곱해 similar에 더해준다. 0.5를 곱해주는 이유는 단어가 일치하는 것보다 단어가 포함되는 것이 정확도가 떨어지기 때문에 0.5를 곱해 유사도 수치를 낮춰주었다. 그 후 위와 마찬가지고 검색어 리스트의 크기로 나누어 주어 유사도 판단을 마무리하고 이를 반환한다.\n",
    "* 다시 search()함수를 보자면 유사도를 계산하기 위한 반복문이 종료되면 모든 url에 대한 유사도 판단이 끝나는데 이를 sorted를 통해 정렬을 하는데 이는 유사도를 key로 정렬하는데 reverse를 True로 설정하여 내림차순으로 정렬되게 하였으며 정렬 후 이를 반환하도록 하였다.\n",
    "* 함수가 끝나고 반환된 리스트를 반복하며 url이름과 유사도를 출력한다. 이미 내림차순으로 정렬되어 있기 때문에 단순히 반복하면 유사도 순으로 출력된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
